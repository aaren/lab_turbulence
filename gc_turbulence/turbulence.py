import os
import glob

import numpy as np

if 'DISPLAY' not in os.environ:
    import matplotlib as mpl
    mpl.use('Agg')

from util import parallel_process
from util import parallel_stub
from util import makedirs_p
from util import ProgressBar


class SingleLayerFrame(object):
    """Each SingleLayerRun is comprised of a series of frames.
    This class represents one of the frames.
    """
    def __init__(self, fname, columns, quiver_format='quiver_{f}.png'):
        """Initialise a frame object.

        Inputs: fname - filename of a piv velocity text file
                columns - {k: v} where k is the name to give the
                          data coming from the column given by v
                keys - a dictionary of {k: v} where k is a header
                       from the data file and v is the column it
                       corresponds to.
                quiver_format - the format of quiver file output
        """
        self.fname = fname
        self.quiver_format = quiver_format
        self.content_start = self.content_line + 2
        self.header_start = self.header_line + 1
        self.columns = columns
        for k in self.columns:
            setattr(self, k, self.data[k])
        # array of times to match dimension of other data
        self.t = np.ones(self.x.shape) * float(self.header['TimeStamp'])

    def find_line(self, string):
        """Find the line on which the string occurs
        and return it."""
        with open(self.fname) as f:
            for line_number, line in enumerate(f.readlines()):
                if string in line:
                    return line_number

    @property
    def header_line(self):
        """Find the line on which the header string occurs
        and return it."""
        header_string = ">>*HEADER*<<"
        return self.find_line(header_string)

    @property
    def content_line(self):
        """Find the line on which the header string occurs
        and return it."""
        content_string = ">>*DATA*<<"
        return self.find_line(content_string)

    @property
    def header(self):
        """Pull header from velocity file and return as dictionary."""
        with open(self.fname) as f:
            content = f.read().splitlines()
            head = content[self.header_start: self.content_start]
            header_info = {}
            for h in head:
                k = h.split(':')[0]
                v = ':'.join(h.split(':')[1:])
                header_info[k] = v
        return header_info

    @property
    def shape(self):
        """Get the gridsize from a piv text file by filtering
        the metadata in the header.
        """
        gridsize = self.header['GridSize']
        x = gridsize.split(', ')[0][-2:]
        z = gridsize.split(', ')[1][-3:-1]
        shape = (int(z), int(x))
        return shape

    @property
    def data(self, delimiter=None):
        """Extract data from a PIV velocity text file.

        N.B. Here I've used the convention (u, w) for (streamwise,
        vertical) velocity, in contrast to the files which use (u, v).
        Similarly for (x, z) rather than (x, y).

        This is to be consistent with meteorological convention.
        """
        if not delimiter:
            # force determine delimiter
            if self.header['FileID'] == 'DSExport.CSV':
                delimiter = ','
            elif self.header['FileID'] == 'DSExport.TAB':
                delimiter = None
        # extract data
        # TODO: dtypes
        D = np.genfromtxt(self.fname,
                          skip_header=self.content_start,
                          delimiter=delimiter)
        shape = self.shape

        # extract from given columns and reshape to sensible
        data = {k: D[:, self.columns[k]].reshape(shape) for k in self.columns}
        return data


# These functions are out here because they need to be pickleable
# for multiprocessing to work. Shame of this is that they can't
# access class state.
@parallel_stub
def instantiateFrame(fname, columns):
    """Create and return a frame instance. Single argument which
    consists of a filename and a queue. The filename is the file
    to create the frame from (as in __init__ of SingleLayer2dFrame).

    the queue is used to store the output

    the pbar is a progress bar that is shared between multiple
    Process() instances.
    """
    frame = SingleLayerFrame(fname=fname, columns=columns)
    return frame


class SingleLayerRun(object):
    """Represents a PIV experiment. Written for a gravity current
    generated by lock release impinging on a homogeneous ambient, but
    perhaps can be made more general.
    """
    # columns to select variables from for single camera run
    columns_2d = {'x': 0,
                  'z': 1,
                  'u': 6,
                  'w': 7}

    # columns to select variables from for two camera run
    columns_3d = {'x': 2,
                  'z': 3,
                  'u': 4,
                  'v': 6,
                  'w': 5}

    def __init__(self, index='test', data_dir='data', rex='*',
                 parallel=True, limits=None, x_lims=(0, -1),
                 stereo=False, caching=False, cache_reload=False,
                 cache_dir=None):
        """Initialise a run.

        Inputs: data_dir - directory containing the velocity files
                index    - the hash code of the run (some unique id
                           in the filenames)
                rex      - some other string found in the filenames
                parallel - whether to use multiprocessing (default True)
                limits   - (start, finish) frame indices to use in selecting
                           the list of files. Default None is to use all
                           the files.
                x_lims   - (first, last) indices of horizontal region to use
                           in each frame. e.g. (10, -10): exclude 10 cells at
                           each side.
                stereo   - boolean, is it a Stereo PIV run or not?
                caching  - boolean, enable caching?
                cache_reload - boolean, reload the data anyway?
                cache_dir - where is the cache file found?
        """
        self.index = index
        self.data_dir = data_dir
        self.rex = rex
        self.parallel = parallel
        self.limits = limits
        self.x_lims = x_lims
        self.stereo = stereo

        if stereo is False:
            self.columns = self.columns_2d
        elif stereo is True:
            self.columns = self.columns_3d

        self.vectors = self.columns.keys() + ['t']

        # default cache_dir
        self.cache_dir = cache_dir or os.path.join(data_dir, 'cache')

        cache_fname = '{index}.npz'.format(index=self.index)
        self.cache_path = os.path.join(self.cache_dir, cache_fname)

        # name for frame storage attribute
        self.lazy_frames = '_lazy_frames'
        self.caching = caching
        # delete the cache file if we are reloading
        self.cache_reload = cache_reload
        cache_exists = os.path.exists(self.cache_path)
        if cache_reload and cache_exists:
            print self.cache_path
            print "there was a cache and i'm deleting it"
            os.remove(self.cache_path)
        # reestablish existence
        cache_exists = os.path.exists(self.cache_path)
        # if caching enabled and the cache file exists and we are
        # not reloading, load the cache file
        if caching and cache_exists:
            print "loading from cache...",
            self.init_load_from_cache()
            print "loaded"
        elif caching and not cache_exists and not cache_reload:
            raise UserWarning("No cache file!")
        # if not caching, load up from the files
        else:
            print "loading from raw data..."
            self.init_not_load_from_cache()

    def init_load_from_cache(self):
        """Initialisation to follow if we are loading directly from
        the cache file."""
        self.load()

    def init_not_load_from_cache(self):
        """Initialisation to follow if we are not loading directly from
        the cache file."""
        f_re = "*{index}{rex}".format(index=self.index, rex=self.rex)
        file_path = os.path.join(self.data_dir, 'data', f_re)
        self.allfiles = sorted(glob.glob(file_path))

        if len(self.allfiles) == 0:
            raise UserWarning('No files found in data dir')
            exit(1)

        if self.limits:
            first, last = self.limits
            self.files = self.allfiles[first:last]
        else:
            self.files = self.allfiles

        self.nfiles = len(self.files)
        self.init_vectors()

    def init_vectors(self):
        """Set instance attributes that correspond to the data structures
        found in the run.

        following this, access e.g. the U velocities with `self.U`
        """
        for v in self.vectors:
            V = np.dstack(getattr(f, v) for f in self.frames)
            setattr(self, v.upper(), V)

        if self.caching:
            self.save()

    @property
    def frames(self):
        """List of frame objects corresponding to the input files.

        Implements lazy property evaluation in that calling self.frames
        will only perform computation once, storing the result in a
        hidden attribute (self.lazy_frames, below).
        """
        # if the storage attribute exists and caching is enabled,
        # just return the storage attribute
        if hasattr(self, self.lazy_frames):
            return getattr(self, self.lazy_frames)

        if self.parallel:
            frames = self.get_frames_parallel()
        elif not self.parallel:
            frames = self.get_frames_serial()

        # save frames to storage attribute (lazy property evaluation)
        setattr(self, self.lazy_frames, frames)

        return frames

    def get_frames_serial(self):
        """Get the frames without multiprocessing. We could just do
        something simple like

            frames = [SingleLayer2dFrame(f) for f in self.files]

        but if we want a progress bar we need to be more explicit.

        Doesn't follow the same pattern as `get_frames_parallel`
        but probably could if we used a queue.
        """
        frames = []
        nfiles = len(self.files)
        pbar = ProgressBar(maxval=nfiles)
        pbar.start()

        for i, fname in enumerate(self.files):
            frame = SingleLayerFrame(fname=fname, columns=self.columns)
            frames.append(frame)
            pbar.update(i)

        pbar.finish()
        return frames

    def get_frames_parallel(self, processors=20):
        """Get the frames with multiprocessing.
        """
        kwargs = [dict(fname=f, columns=self.columns) for f in self.files]
        frames = parallel_process(instantiateFrame,
                                  kwarglist=kwargs,
                                  processors=processors)
        if type(frames) is not list:
            raise UserWarning('frames is not list!')
        # order based on filename
        sorted_frames = sorted(frames, key=lambda f: f.fname)
        return sorted_frames

    def save(self):
        """Save run arrays to disk."""
        makedirs_p(os.path.dirname(self.cache_path))
        arrays = {v.upper(): getattr(self, v.upper()) for v in self.vectors}
        np.savez(self.cache_path, **arrays)
        print "saved!"

    def load(self):
        """Load run arrays from disk.

        Useful to avoid re-extracting the velocity data
        repeatedly.
        """
        arrays = np.load(self.cache_path)
        for v in arrays:
            setattr(self, v, arrays[v])

    def toggle_cache(self, what=None):
        """Toggle the state of run caching by changing the
        value of self.caching.

        Called with no arguments, reverses value of self.caching.

        Called with boolean argument, sets self.caching to that
        value.
        """
        if what is None:
            self.caching = not(self.caching)
            return
        else:
            if type(what) is not bool:
                raise UserWarning('cache value must be boolean')
                return
            else:
                self.caching = what
                return

    def reload(self):
        """Force reload of frames."""
        if self.parallel:
            frames = self.get_frames_parallel()
        elif not self.parallel:
            frames = self.get_frames_serial()
        setattr(self, self.lazy_frames, frames)
        if self.caching:
            self.save()
